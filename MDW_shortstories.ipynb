{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,codecs,scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = \"/Users/eunjilee/Desktop/cesta/short_stories_project/metadata_files/metadata_shortstories_text.csv\"\n",
    "sdir = \"/Users/eunjilee/Desktop/cesta/short_stories_project/short_stories_files\"\n",
    "ofn = \"/Users/eunjilee/Desktop/cesta/short_stories_project/outputs/short_stories_files_mdw.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a spreadsheet into a list of lists\n",
    "\n",
    "def sheet2lol(fn,separator=\",\"):\n",
    "    f=codecs.open(fn,encoding=\"utf-8-sig\")\n",
    "    text=f.read()\n",
    "    f.close()\n",
    "    lines = text.splitlines()\n",
    "    lol = []\n",
    "    \n",
    "    for l in lines:\n",
    "        l = l.split(separator)\n",
    "        lol.append(l)\n",
    "    return lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a directory into a list of its text files\n",
    "# Your files must all end with .txt\n",
    "\n",
    "def dir2files(somedirectory,path=False):\n",
    "    if path == False:\n",
    "        files = os.listdir(somedirectory)\n",
    "    else:\n",
    "        files = os.listdir(somedirectory)\n",
    "        files = [os.path.join(somedirectory,f) for f in files]\n",
    "    for i in files[:]:\n",
    "            if not i.endswith(\".txt\"):\n",
    "                files.remove(i)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean words; you may wish to adjust the parameters here\n",
    "# Usually want to make lowercase, but might not with names\n",
    "\n",
    "def cleanword(w,lower=True):\n",
    "    if lower: \n",
    "        w=w.lower()\n",
    "    while w and not w[0].isalpha():\n",
    "        w=w[1:]\n",
    "    while w and not w[-1].isalpha():\n",
    "        w=w[:-1]\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a filename into a cleaned up list of its words\n",
    "\n",
    "def file2cleanwords(filename):\n",
    "    f=codecs.open(filename,encoding=\"utf-8\")\n",
    "    text=f.read()\n",
    "    f.close()\n",
    "    text=text.encode('utf8')\n",
    "    # Get rid of curly quotes and apostrophes\n",
    "    text = text.decode()\n",
    "    text = text.replace(\"‘\",\"'\").replace(\"’\",\"'\").replace('“','\"').replace(\"”\",'\"').replace('\\xa0', ' ')\n",
    "    words = text.split()\n",
    "    words = [cleanword(w) for w in words]\n",
    "\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique values in a spreadsheet column\n",
    "# (Actually a list of lists now, but same idea)\n",
    "\n",
    "def unique_col_values(somedf,col_num,header=True):\n",
    "    values = []\n",
    "    if header == True:\n",
    "        somedf = somedf[1:]\n",
    "    for row in somedf:\n",
    "        v = row[col_num]\n",
    "        if v not in values:\n",
    "            values.append(v)\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn your corpora into wordcount dictionaries\n",
    "# This will be a dictionary of dictionaries\n",
    "# For this to work as is, your metadata table must have filenames but not path names\n",
    "\n",
    "def makecorpusdicts(somedir,metatable,meta_col_num,fn_col_num):\n",
    "    corp_dict = {}\n",
    "    files = dir2files(somedir)\n",
    "    corpora = unique_col_values(metatable,meta_col_num)\n",
    "\n",
    "    for c in corpora:\n",
    "        corp_dict[c] = {}\n",
    "    for row in metatable[1:]:\n",
    "        fn = os.path.join(somedir,row[fn_col_num])\n",
    "        words = file2cleanwords(fn)\n",
    "        cd = str(row[meta_col_num])\n",
    "        for w in words:\n",
    "            if w in corp_dict[cd]:\n",
    "                corp_dict[cd][w] += 1\n",
    "            else:\n",
    "                corp_dict[cd][w] = 1\n",
    "\n",
    "    return corp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get word counts for your copora from the \"makecorpusdicts\" output\n",
    "# This would work for any such dictionary of dictionaries\n",
    "\n",
    "def get_wcd(corp_dict):\n",
    "    wcd = {}\n",
    "    for d in corp_dict:\n",
    "        tempd = dict(corp_dict[d])\n",
    "        wcd[d] = sum(tempd.values())\n",
    "    return wcd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a directory of text files into an overall dictionary of word counts\n",
    "\n",
    "def dir2counts(somedir):\n",
    "    counts = {}\n",
    "    files = dir2files(somedir,path=True)\n",
    "    for f in files:\n",
    "        words = file2cleanwords(f)\n",
    "        for w in words:\n",
    "            if w in counts:\n",
    "                counts[w] += 1\n",
    "            else:\n",
    "                counts[w] = 1\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For MDW, we want word rates\n",
    "# I.e. how often a word appears given the word count\n",
    "# This converts a counts dictionary to a rates dictionary\n",
    "\n",
    "def counts2rates(somecountdict):\n",
    "    rates = dict(somecountdict)\n",
    "    total = sum(somecountdict.values())\n",
    "    for key in rates:\n",
    "        rates[key] = float(rates[key])/total\n",
    "    return rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make your dictionaries a term document matrix\n",
    "# This gives you a good way to A) produce writable output\n",
    "# And B), go through and get MDW later on\n",
    "# min_obs refers to total observations across all corpora\n",
    "\n",
    "def dicts2tdm(dictofcountdicts,min_obs=0,no_numbers=False):\n",
    "    # I'm removing any corpus that had no actual values found; might not want to do this\n",
    "    for d in dictofcountdicts:\n",
    "        if sum(dictofcountdicts[d].values()) == 0:\n",
    "            del dictofcountdicts[d]\n",
    "    tdm = [['token_']+list(dictofcountdicts.keys())]\n",
    "    all_words = []\n",
    "    for d in dictofcountdicts:\n",
    "        for w in list(dictofcountdicts[d].keys()):\n",
    "            if w not in all_words:\n",
    "                all_words.append(w)\n",
    "    for w in all_words:\n",
    "        row=[w]\n",
    "        for col in tdm[0][1:]:\n",
    "            if w in dictofcountdicts[col]:\n",
    "                row.append(dictofcountdicts[col][w])\n",
    "            else:\n",
    "                row.append(0)\n",
    "        tdm.append(row)\n",
    "    if no_numbers == True:\n",
    "        for row in tdm[1:]:\n",
    "            if is_number(row[0]):\n",
    "                tdm.remove(row)\n",
    "    for row in tdm[1:]:\n",
    "        if sum(row[1:]) < min_obs:\n",
    "            tdm.remove(row)\n",
    "    return tdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Melts' the tdm\n",
    "# Which means columns are types of data instead of particular instances of that type\n",
    "# E.g. instead of columns for \"Western\" and \"Sci-Fi\" you'd have \"Genre\" and list the two types under it for each word\n",
    "\n",
    "def tdm_melter(sometdm):\n",
    "    old_headers = sometdm[0]\n",
    "    melt = [['token_','Corpus','Observations']]\n",
    "    for row in sometdm[1:]:\n",
    "        for n,col in enumerate(row[1:],1):\n",
    "            ol = [row[0],old_headers[n],row[n]]\n",
    "            melt.append(ol)\n",
    "    return melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a Fishers exact test, mdw style\n",
    "\n",
    "def get_fishers(melted_tdm_row,wcd,word_rates,obs_exp=False,alternative=\"greater\"):\n",
    "    corpus = melted_tdm_row[1]\n",
    "    wc = wcd[corpus]\n",
    "    word = melted_tdm_row[0]\n",
    "    rate = word_rates[word]\n",
    "    a = melted_tdm_row[2]\n",
    "    b = wc-a\n",
    "    c = round(rate*wc)\n",
    "    d = wc-c\n",
    "    p = scipy.stats.fisher_exact([[a,b],[c,d]],alternative=alternative)[1]\n",
    "    if obs_exp == True:\n",
    "        if c != 0:\n",
    "            oe = a/c\n",
    "        else:\n",
    "            oe = \"Inf\"\n",
    "        p = (p,oe)\n",
    "    return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the actual mdw data and append to the tdm\n",
    "\n",
    "def add_mdw(melted_tdm,wcd,word_rates,obs_exp=True,alpha=.05,alternative=\"greater\"):\n",
    "    melted_tdm[0].extend(['p_value','Obs/Exp'])\n",
    "    for row in melted_tdm[1:]:\n",
    "        duple = get_fishers(row,wcd,word_rates,obs_exp=obs_exp,alternative=alternative)\n",
    "        p = duple[0]\n",
    "        if p >= alpha:\n",
    "            melted_tdm.remove(row)\n",
    "        else:\n",
    "            row.extend([p,duple[1]])\n",
    "    return melted_tdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turns our list of lists into a spreadsheet, located wherever you put it\n",
    "\n",
    "def lol_to_file(lol,output_filename,separator=\"\\t\"):\n",
    "    with open(output_filename,'w') as output_file:\n",
    "        for row in lol:\n",
    "            row = [str(i) for i in row]\n",
    "            ostr = \"\\t\".join(row) + \"\\n\"\n",
    "            output_file.write(ostr)\n",
    "    print (\"Wrote the file \" + output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the functions above to get MDW from a metadata table and a corpus\n",
    "# If there's an equals sign in any of the inputs, you don't have to write anything unless you want to change default\n",
    "# Otherwise, you have to write something\n",
    "\n",
    "def get_mdw(metadata_table_fn,metadata_column_num,filename_col_num,source_directory,output_filename,\n",
    "            metadata_table_separator=\",\",keep_uppercase=False,minimum_observations=0,fishers_alternative=\"greater\",\n",
    "            alpha=.05,output_filename_separator=\"\\t\"):\n",
    "    print (\"Reading metadata table...\")\n",
    "    metatable = sheet2lol(metadata_table_fn,separator=metadata_table_separator)\n",
    "    \n",
    "    print (\"Making a wordcount dictionary for each subcorpus...\")\n",
    "    corp_dict = makecorpusdicts(source_directory,metatable,\n",
    "                                meta_col_num = metadata_column_num,fn_col_num = filename_col_num)\n",
    "    \n",
    "    print (\"Getting total word counts for your subcorpora...\")\n",
    "    wcd = get_wcd(corp_dict)\n",
    "    \n",
    "    print (\"Getting word counts for the full corpus...\")\n",
    "    counts = dir2counts(source_directory)\n",
    "    \n",
    "    print (\"Coverting those counts to rates...\")\n",
    "    rates = counts2rates(counts)\n",
    "    \n",
    "    print (\"Making a tdm out of the individual corpus counts...\")\n",
    "    tdm = dicts2tdm(corp_dict,min_obs=minimum_observations)\n",
    "    \n",
    "    print (\"Melting the tdm...\")\n",
    "    melted_tdm = tdm_melter(tdm)\n",
    "    \n",
    "    print (\"Getting mdw data...\")\n",
    "    mdw = add_mdw(melted_tdm,wcd,rates,alpha=alpha,alternative=fishers_alternative)\n",
    "    \n",
    "    print (\"Writing data to file...\")\n",
    "    lol_to_file(mdw,output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading metadata table...\n",
      "Making a wordcount dictionary for each subcorpus...\n",
      "Getting total word counts for your subcorpora...\n",
      "Getting word counts for the full corpus...\n",
      "Coverting those counts to rates...\n",
      "Making a tdm out of the individual corpus counts...\n",
      "Melting the tdm...\n",
      "Getting mdw data...\n",
      "Writing data to file...\n",
      "Wrote the file /Users/eunjilee/Desktop/cesta/short_stories_project/outputs/short_stories_files_mdw.tsv\n"
     ]
    }
   ],
   "source": [
    "get_mdw(metadata,metadata_column_num=1,filename_col_num=0,\n",
    "        source_directory=sdir,output_filename=ofn,minimum_observations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
