{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, codecs, scipy.stats, csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = \"/Users/eunjilee/Desktop/cesta/short_stories_project/metadata_files/metadata_shortstories_pos.csv\"\n",
    "sdir = \"/Users/eunjilee/Desktop/cesta/short_stories_project/pos_tagged\"\n",
    "ofn = \"/Users/eunjilee/Desktop/cesta/short_stories_project/outputs/pos_tagged_mdpos.tsv\"\n",
    "pos_tag_file = \"/Users/eunjilee/Desktop/cesta/short_stories_project/pos_tagged\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a spreadsheet into a list of lists\n",
    "\n",
    "def sheet2lol(fn,separator=\",\"):\n",
    "    f=codecs.open(fn,encoding=\"utf-8-sig\")\n",
    "    text=f.read()\n",
    "    f.close()\n",
    "    lines = text.splitlines()\n",
    "    lol = []\n",
    "    for l in lines:\n",
    "        l = l.split(separator)\n",
    "        lol.append(l)\n",
    "    return lol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a directory into a list of its text files\n",
    "# Your files must all end with .txt\n",
    "\n",
    "def dir2files(somedirectory,path=False, extension = '.csv'):\n",
    "    if path == False:\n",
    "        files = os.listdir(somedirectory)\n",
    "    else:\n",
    "        files = os.listdir(somedirectory)\n",
    "        files = [os.path.join(somedirectory,f) for f in files]\n",
    "    for i in files[:]:\n",
    "            if not i.endswith(extension):\n",
    "                files.remove(i)\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean words; you may wish to adjust the parameters here\n",
    "# Usually want to make lowercase, but might not with names\n",
    "\n",
    "def cleanpos(pos, lower=True):\n",
    "    if pos.endswith(\"$\"):\n",
    "        pos = pos[:-2]\n",
    "    return pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a filename into a cleaned up list of its words\n",
    "\n",
    "def file2cleanpos(filename, separator = \"\\t\", specific_pos = True):\n",
    "    pos_lol = sheet2lol(filename, separator)\n",
    "\n",
    "    if specific_pos == True:\n",
    "        col_num = 2\n",
    "    else:\n",
    "        col_num = 1\n",
    "\n",
    "    text = []\n",
    "\n",
    "    for a_list in pos_lol:\n",
    "        text.append(a_list[col_num])\n",
    "\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique values in a spreadsheet column\n",
    "# (Actually a list of lists now, but same idea)\n",
    "\n",
    "def unique_col_values(somedf,col_num,header=True):\n",
    "    values = []\n",
    "    if header == True:\n",
    "        somedf = somedf[1:]\n",
    "    for row in somedf:\n",
    "        v = row[col_num]\n",
    "        if v not in values:\n",
    "            values.append(v)\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn your corpora into wordcount dictionaries\n",
    "# This will be a dictionary of dictionaries\n",
    "# For this to work as is, your metadata table must have filenames but not path names\n",
    "\n",
    "def makecorpusdicts(somedir,metatable,meta_col_num,fn_col_num):\n",
    "    corp_dict = {}\n",
    "    files = dir2files(somedir, extension = \".tsv\")\n",
    "    corpora = unique_col_values(metatable,meta_col_num)\n",
    "\n",
    "\n",
    "    for c in corpora:\n",
    "        corp_dict[c] = {}\n",
    "    for row in metatable[1:]:\n",
    "        fn = os.path.join(somedir,row[fn_col_num])\n",
    "        tags = file2cleanpos(fn)\n",
    "\n",
    "        cd = str(row[meta_col_num])\n",
    "        for tag in tags:\n",
    "            if tag in corp_dict[cd]:\n",
    "                corp_dict[cd][tag] += 1\n",
    "            else:\n",
    "                corp_dict[cd][tag] = 1\n",
    "\n",
    "    return corp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pos counts for your copora from the \"makecorpusdicts\" output\n",
    "# This would work for any such dictionary of dictionaries\n",
    "\n",
    "def get_pos_dict(corp_dict):\n",
    "    pos_dict = {}\n",
    "    for d in corp_dict:\n",
    "        tempd = dict(corp_dict[d])\n",
    "        pos_dict[d] = sum(tempd.values())\n",
    "\n",
    "    return pos_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a directory of text files into an overall dictionary of word counts\n",
    "\n",
    "def dir2counts(somedir):\n",
    "    counts = {}\n",
    "    files = dir2files(somedir, path=True, extension = '.tsv')\n",
    "\n",
    "    for f in files:\n",
    "        tags = file2cleanpos(f)\n",
    "        for tag in tags:\n",
    "            if tag in counts:\n",
    "                counts[tag] += 1\n",
    "            else:\n",
    "                counts[tag] = 1\n",
    "\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For MDPOS, we want POS rates\n",
    "# I.e. how often a POS appears given the word count\n",
    "# This converts a counts dictionary to a rates dictionary\n",
    "\n",
    "def counts2rates(somecountdict):\n",
    "    rates = dict(somecountdict)\n",
    "    total = sum(somecountdict.values())\n",
    "    for key in rates:\n",
    "        rates[key] = float(rates[key])/total\n",
    "    return rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make your dictionaries a term document matrix\n",
    "# This gives you a good way to A) produce writable output\n",
    "# And B), go through and get MDW later on\n",
    "# min_obs refers to total observations across all corpora\n",
    "\n",
    "def dicts2tdm(dictofcountdicts, min_obs=0, no_numbers=False):\n",
    "    # I'm removing any corpus that had no actual values found; might not want to do this\n",
    "    for d in dictofcountdicts:\n",
    "        if sum(dictofcountdicts[d].values()) == 0:\n",
    "            del dictofcountdicts[d]\n",
    "    tdm = [['token_']+list(dictofcountdicts.keys())]\n",
    "    all_pos = []\n",
    "    for d in dictofcountdicts:\n",
    "        for w in list(dictofcountdicts[d].keys()):\n",
    "            if w not in all_pos:\n",
    "                all_pos.append(w)\n",
    "    for w in all_pos:\n",
    "        row=[w]\n",
    "        for col in tdm[0][1:]:\n",
    "            if w in dictofcountdicts[col]:\n",
    "                row.append(dictofcountdicts[col][w])\n",
    "            else:\n",
    "                row.append(0)\n",
    "        tdm.append(row)\n",
    "    if no_numbers == True:\n",
    "        for row in tdm[1:]:\n",
    "            if is_number(row[0]):\n",
    "                tdm.remove(row)\n",
    "    for row in tdm[1:]:\n",
    "        if sum(row[1:]) < min_obs:\n",
    "            tdm.remove(row)\n",
    "    return tdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Melts' the tdm\n",
    "# Which means columns are types of data instead of particular instances of that type\n",
    "# E.g. instead of columns for \"Western\" and \"Sci-Fi\" you'd have \"Genre\" and list the two types under it for each word\n",
    "\n",
    "def tdm_melter(sometdm):\n",
    "    old_headers = sometdm[0]\n",
    "    melt = [['token_','Corpus','Observations']]\n",
    "    for row in sometdm[1:]:\n",
    "        for n,col in enumerate(row[1:],1):\n",
    "            ol = [row[0],old_headers[n],row[n]]\n",
    "            melt.append(ol)\n",
    "    return melt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do a Fishers exact test, mdpos style\n",
    "\n",
    "def get_fishers(melted_tdm_row, wcd, word_rates, obs_exp=False, alternative=\"greater\"):\n",
    "    corpus = melted_tdm_row[1]\n",
    "    wc = wcd[corpus]\n",
    "    word = melted_tdm_row[0]\n",
    "    rate = word_rates[word]\n",
    "    a = melted_tdm_row[2]\n",
    "    b = wc-a\n",
    "    c = round(rate*wc)\n",
    "    d = wc-c\n",
    "    p = scipy.stats.fisher_exact([[a,b],[c,d]],alternative=alternative)[1]\n",
    "    if obs_exp == True:\n",
    "        if c != 0:\n",
    "            oe = a/c\n",
    "        else:\n",
    "            oe = \"Inf\"\n",
    "        p = (p,oe)\n",
    "    return p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the actual mdw data and append to the tdm\n",
    "\n",
    "def add_mdw(melted_tdm,wcd,word_rates,obs_exp=True,alpha=.05,alternative=\"greater\"):\n",
    "    melted_tdm[0].extend(['p_value','Obs/Exp'])\n",
    "    for row in melted_tdm[1:]:\n",
    "        duple = get_fishers(row,wcd,word_rates,obs_exp=obs_exp,alternative=alternative)\n",
    "        p = duple[0]\n",
    "        if p >= alpha:\n",
    "            melted_tdm.remove(row)\n",
    "        else:\n",
    "            row.extend([p,duple[1]])\n",
    "    return melted_tdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turns our list of lists into a spreadsheet, located wherever you put it\n",
    "# tab separation\n",
    "\n",
    "def lol_to_file(lol,output_filename,separator=\"\\t\"):\n",
    "    pos_list = []\n",
    "    \n",
    "    with open(output_filename,'w') as output_file:\n",
    "        for row in lol:\n",
    "            row = [str(i) for i in row]\n",
    "            ostr = \"\\t\".join(row) + \"\\n\"\n",
    "            output_file.write(ostr)\n",
    "            \n",
    "            pos_list.append(row[0])\n",
    "            #poslist_to_wordlist(pos_list)\n",
    "    print(pos_list)\n",
    "    print (\"Wrote the file \" + output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poslist_to_wordlist(pos_list):\n",
    "    files = dir2files(pos_tag_file, path = True, extension = '.tsv')\n",
    "    print(files)\n",
    "    for file in files:\n",
    "        with open(file) as f:\n",
    "            reader = csv.DictReader(f, dialect='excel-tab')\n",
    "            print(row)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Otherwise, you have to write something\n",
    "\n",
    "def get_mdpos(metadata_table_fn,metadata_column_num,filename_col_num,source_directory,\n",
    "              output_filename,metadata_table_separator=\",\",keep_uppercase=False,minimum_observations=0,\n",
    "              fishers_alternative=\"greater\",alpha=.05,output_filename_separator=\"\\t\"):\n",
    "    print (\"Reading metadata table...\")\n",
    "    metatable = sheet2lol(metadata_table_fn,separator=metadata_table_separator)\n",
    "    \n",
    "    print (\"Making a wordcount dictionary for each subcorpus...\")\n",
    "    corp_dict = makecorpusdicts(source_directory,metatable,meta_col_num = metadata_column_num,\n",
    "                                fn_col_num = filename_col_num)\n",
    "    \n",
    "    print (\"Getting total word counts for your subcorpora...\")\n",
    "    wcd = get_pos_dict(corp_dict)\n",
    "    \n",
    "    print (\"Getting word counts for the full corpus...\")\n",
    "    counts = dir2counts(source_directory)\n",
    "    \n",
    "    print (\"Coverting those counts to rates...\")\n",
    "    rates = counts2rates(counts)\n",
    "    \n",
    "    print (\"Making a tdm out of the individual corpus counts...\")\n",
    "    tdm = dicts2tdm(corp_dict,min_obs=minimum_observations)\n",
    "    \n",
    "    print (\"Melting the tdm...\")\n",
    "    melted_tdm = tdm_melter(tdm)\n",
    "    \n",
    "    print (\"Getting mdw data...\")\n",
    "    mdw = add_mdw(melted_tdm,wcd,rates,alpha=alpha,alternative=fishers_alternative)\n",
    "    \n",
    "    print (\"Writing data to file...\")\n",
    "    lol_to_file(mdw,output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading metadata table...\n",
      "Making a wordcount dictionary for each subcorpus...\n",
      "Getting total word counts for your subcorpora...\n",
      "Getting word counts for the full corpus...\n",
      "Coverting those counts to rates...\n",
      "Making a tdm out of the individual corpus counts...\n",
      "Melting the tdm...\n",
      "Getting mdw data...\n",
      "Writing data to file...\n",
      "['token_', 'RB', 'IN', 'DT', 'NN', 'VBD', ',', 'PRP', 'VB', 'JJ', 'HYPH', 'NNP', '.', 'PRP$', 'NNS', 'CC', 'VBG', 'VBN', 'VBZ', 'TO', 'EX', '``', 'UH', \"''\", 'VBP', 'POS', 'XX', 'JJS']\n",
      "Wrote the file /Users/eunjilee/Desktop/cesta/short_stories_project/outputs/pos_tagged_mdpos.tsv\n"
     ]
    }
   ],
   "source": [
    "get_mdpos(metadata,metadata_column_num=1,filename_col_num=0,source_directory=sdir,\n",
    "          output_filename=ofn,minimum_observations=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
